---
title: "Longevity"
author: "C le"
output: html_document
---



# Project Overview
Two sample Mendelian Randomization Analysis on GWAS of human lifespan looking at new and known exposure relationships related to longevity outcomes.

## A. Exposures

Exposures are obtained from the mrbase.org website from the following catalogs
  - NHGRI-EBI GWAS catalog
  - MR BASE GWAS catalog
  - Gene Expression QTLs
  - Protein Level QTLs
  - Metabolite Level OTLs
  - Methylation Level QTLs

## B. Outcomes

### I. First Outcome: cases 90

Outcome Data obtained from CPMC that was utilized in Deelen et al., 2019 (https://pubmed.ncbi.nlm.nih.gov/31413261/). Exposure - Outcome relationships will be examined in persons whose longevity is in the 90th percentile using the rest of the cohort as the control.

Download Deelen outcomes and files for rsID mapping.

```{r, eval = FALSE}
#Mapping file from EasyQC. Place is data/outcomes/
system("wget https://homepages.uni-regensburg.de/~wit59712/easyqc/1000g/rsmid_map.1000G_ALL_p1v3.merged_mach_impute.v3.mergeindels.txt.gz")

#Deelen GWAS outcomes
system("wget ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/DeelenJ_31413261_GCST008598/Results_90th_percentile.txt.gz")

system("wget ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/DeelenJ_31413261_GCST008599/Results_99th_percentile.txt.gz")

```

Map cptids to rsids using EasyQC map files

```{r}
require(tidyverse)
outcome <- read_delim("data/outcomes/Results_90th_percentile.txt.gz", delim = "\t")
#create SNPorder to track dups caused by multiple matches
outcome <- outcome %>%
  mutate(SNPorder = seq_along(SNP))

mapfile <- read_delim("data/outcomes/rsmid_map.1000G_ALL_p1v3.merged_mach_impute.v3.mergeindels.txt", delim = "\t")

#rsmid contains rsids
mapfile %>%
  filter(grepl("^rs.*", rsmid)) %>%
  summarize(n())

outcome <- outcome %>%
  left_join(mapfile, by = c("SNP" = "cptid"))

# All 1:1 merge, no dups induced
outcome %>%
  filter(duplicated(SNPorder)) %>%
  summarize(n())
#Chr matches with chr
outcome %>%
  filter(Chr != chr) %>%
  summarize(n()) 
#Position mismatches with pos = 2
outcome %>%
  filter(Position != pos) %>%
  summarize(n()) 
map_int(outcome, function(x) sum(is.na(x))) #4 missing rsmids
#remove missing rsids, mismatching chr and pos, rename vars,
# remove unneeded vars
outcome <- outcome %>%
  filter(!is.na(rsmid)) %>%
  filter(Chr == chr) %>%
  filter(Position == pos) %>%
  rename(rsid = rsmid, pval = "P-value", cptid = SNP) %>%
  mutate(chr = NULL) %>%
  mutate(pos = NULL) %>%
  mutate(SNPorder = NULL) %>%
  select(rsid, everything())

write_csv(outcome ,"data/outcomes/cases90rsid.csv")

```

### II. Second outcome: cases 99

Using data from section I, compare persons in the 90th percentile with persons in the 99th percentile. 

Map cptids to rsids using EasyQC map files

```{r}
require(tidyverse)
outcome <- read_delim("data/outcomes/Results_99th_percentile.txt.gz", delim = "\t")
#create SNPorder to track dups caused by multiple matches
outcome <- outcome %>%
  mutate(SNPorder = seq_along(SNP))

mapfile <- read_delim("data/outcomes/rsmid_map.1000G_ALL_p1v3.merged_mach_impute.v3.mergeindels.txt", delim = "\t")

#rsmid contains rsids
mapfile %>%
  filter(grepl("^rs.*", rsmid)) %>%
  summarize(n())

outcome <- outcome %>%
  left_join(mapfile, by = c("SNP" = "cptid"))

# All 1:1 merge, no dups induced
outcome %>%
  filter(duplicated(SNPorder)) %>%
  summarize(n())
#Chr matches with chr
outcome %>%
  filter(Chr != chr) %>%
  summarize(n()) 
#Position mismatches with pos = 2
outcome %>%
  filter(Position != pos) %>%
  summarize(n()) 
map_int(outcome, function(x) sum(is.na(x))) #4 missing rsmids
#remove missing rsids, mismatching chr and pos, rename vars,
# remove unneeded vars
outcome <- outcome %>%
  filter(!is.na(rsmid)) %>%
  filter(Chr == chr) %>%
  filter(Position == pos) %>%
  rename(rsid = rsmid, pval = "P-value", cptid = SNP) %>%
  mutate(chr = NULL) %>%
  mutate(pos = NULL) %>%
  mutate(SNPorder = NULL) %>%
  select(rsid, everything())

write_csv(outcome ,"data/outcomes/cases99rsid.csv")

```


### III. Third Outcome: UK Biobank

Compare persons in the 90th percentile from section I to those in the 90th percentile from the UK Biobank

### IV. Fourth Outcome: UK Biobank Parental Longevity
## C. Preparation of Data

### I. Load Libraries
```{r}
library(TwoSampleMR)
library(MRInstruments)
library(tidyverse) #so we can use purrr::map, and no, not just because I got cats
library(knitr)
library(ieugwasr)
library(arsenal)
library(tidyverse) #why loaded twice?
```

###II.  Exposures from each catalog


#### a. GWAS Catalog

```{r, cache = TRUE}

#cache = True will create a folder that saves objects, and if objects and code aren't updated, this code chunk will not re-run. This is good for long-running code sections.
#import gwas catalog into R
data(gwas_catalog)
#gwas_catalog

#create a vector of unique gwas phenotypes
gwas_unique <- gwas_catalog %>%
  filter(!duplicated(Phenotype)) %>%
  pull(Phenotype)
# 3590 unique phenotypes in catalog

#make a for loop to create a database of exposure SNPs formatted for exposure data and clumped
#Initialize a list to save results. The problem with creating an empty dataframe with data.frame() is that it doesn't preallocate memory for 3590 rows. Instead, it creates an empty DF with zero rows.

exposures_gwas <- vector(mode = "list", length = length(gwas_unique))
for(i in seq_along(gwas_unique)){
  #you can test with for(i in 1:5)
# for(i in 1 : length(gwas_unique)) {
  #format exposure data and clump by LD r2 <0.001 to reduce covariance
  #combined both steps together. Send output to each element of list
  exposures_gwas[[i]] <- gwas_catalog %>%
    filter(Phenotype == gwas_unique[i]) %>%
    format_data %>%
    clump_data
  
  print(paste0("Last successful run was ", gwas_unique[i], 
               " which is iterator ", i))
}

#rbind list elements into DF
#old way of doing things
#exposures_gwas_DF <- do.call(rbind, exposures_gwas)
#faster way of doing things with dplyr
exposures_gwas_DF <- bind_rows(exposures_gwas)

#check that 'phenotypes' is the same as the last entry in gwas_unique
# gwas_unique[3590]
# gwas_phenotypes$Phenotype

# 
# save(exposures_gwas, file = "C:/Users/me/Desktop/MPH/Internship/CPMC/exposures_gwas.Rdata")
```

#### b. MR Base GWAS Catalog

#### c. Gene Expression QTLs
should we search for gene and tissue together or just gene?
- below is search by gene and tissue together
```{r, cache = TRUE}

#import Gene Expression QTLs list
data(gtex_eqtl)
gtex_eqtl


#create a list of unique gene names

genes_unique <- gtex_eqtl[!duplicated(gtex_eqtl$gene_name),] %>% pull(gene_name)

# 32432 unique gene names
```


For loop
```{r, cache = TRUE}
genes_table <- gtex_eqtl[!duplicated(gtex_eqtl$gene_name),]

exposures_genes <- data.frame()
for(i in 17583: length(genes_unique)){
  genes <- subset(gtex_eqtl, gene_name == genes_unique[i])

  #create a separate clumping step in case LD lookup times out
  genes_format <- format_gtex_eqtl(genes) %>% clump_data()

  exposures_genes <- rbind(exposures_genes, genes_format)
}

saveRDS(exposures_genes, file = "C:/Users/me/Desktop/MPH/Internship/CPMC/exposures_genes.rds")
```


try as a function

```{r, cache = TRUE}
genes_clump <- function(genes){
  gene <- subset(gtex_eqtl, gene_name == genes) %>% format_gtex_eqtl() %>% clump_data()
}

gen <- genes_unique[1:10]

test <- lapply(gen, genes_clump)
```

try local clumping
reference downloaded at : http://fileserve.mrcieu.ac.uk/ld/1kg.v3.tgz
```{r,cache=TRUE}


#format for ld_clumping

gene_dat <-subset(gtex_eqtl, gene_name == "RP4-669L17.10") %>% 
  format_gtex_eqtl() %>%
  rename(rsid = SNP,
         pval = pval.exposure,
         id = id.exposure) %>%
  ld_clump(plink_bin = genetics.binaRies::get_plink_binary(), bfile = "C:/Users/me/Desktop/MPH/Internship/CPMC/Data/LD_reference/EUR", #no need to include extensions
           clump_kb = 1000, clump_r2 = .001, 
           clump_p = 1, pop = "EUR") 
 

#same results
```



#### d. Protein Level QTLs

Instead of retrieving via API, do ld clumping locally using the same reference population "EUR" from 1000 genomes

```{r, cache=TRUE}
#import Protein Level QTLs into R
data(proteomic_qtls)
proteomic_qtls

#create a list of unique protein analyte & make a list

proteins_unique <- proteomic_qtls[!duplicated(proteomic_qtls$analyte),] %>% pull(analyte)


exposures_protein <- data.frame()
for(i in 1 : length(proteins_unique)) {
  
  proteins_phenotypes<- subset(proteomic_qtls, analyte == proteins_unique[i])
  
  #format exposure data and clump by LD r2 <0.001 to reduce covariance
  proteins_format<- proteins_phenotypes %>% format_proteomic_qtls() %>%
    rename(rsid = SNP,
         pval = pval.exposure,
         id = id.exposure)
  
  proteins_clump <- ld_clump(proteins_format, 
                             plink_bin = genetics.binaRies::get_plink_binary(), 
                             bfile = "C:/Users/me/Desktop/MPH/Internship/CPMC/Data/LD_reference/EUR",
                             #no need to include extensions
                             clump_kb = 1000, clump_r2 = .001, clump_p = 1, pop = "EUR")

  exposures_protein <- rbind(exposures_protein, proteins_clump)
    
}

exposures_protein <- exposures_protein %>% rename (SNP = rsid, id.exposure = id)

```



For Loops
```{r, cache = TRUE}

#import Protein Level QTLs into R
data(proteomic_qtls)
proteomic_qtls

#create a list of unique protein analyte & make a list

proteins_unique <- proteomic_qtls[!duplicated(proteomic_qtls$analyte),] %>% pull(analyte)
#  unique phenotypes in catalog



#make a for loop to create a database of exposure SNPs formatted for exposure data and clumped
exposures_proteins_API <- data.frame()
for(i in 1 : length(proteins_unique)) {
  
  proteins_phenotypes_API<- subset(proteomic_qtls, analyte == proteins_unique[i])
  
  #format exposure data and clump by LD r2 <0.001 to reduce covariance
  proteins_format_API<- proteins_phenotypes_API %>% format_proteomic_qtls() %>% clump_data()

  exposures_proteins_API <- rbind(exposures_proteins_API, proteins_format_API)
    
}


# check that 'phenotypes' is the same as the last entry in gwas_unique
proteins_unique[47]
proteins_phenotypes$analyte


saveRDS(exposures_proteins_API, file = "C:/Users/me/Desktop/MPH/Internship/CPMC/exposures_proteins.rds")
```

Both dataframes are the same. 

```{r,cache=TRUE}
identical(exposures_protein$rsid, exposures_proteins_API$rsid)
```


#### e. Metabolite Level OTLs


```{r, cache=TRUE}

#import Metabolite Level QTLs into R
data(metab_qtls)
metab_qtls

#create a list of unique metabolomic phenotype & make a list

metabolites_unique <- metab_qtls[!duplicated(metab_qtls$phenotype),] %>% pull(phenotype)
# 121 unique phenotypes in catalog



#make a for loop to create a database of exposure SNPs formatted for exposure data and clumped
exposures_metabolite <- data.frame()
for(i in 1 : length(metabolites_unique)) {
  
  metabolites_phenotypes<- subset(metab_qtls, phenotype == metabolites_unique[i]) %>% 
    format_metab_qtls() %>% 
    rename(rsid = SNP,
         pval = pval.exposure,
         id = id.exposure) %>%
    ld_clump( plink_bin = genetics.binaRies::get_plink_binary(), 
              bfile = "C:/Users/me/Desktop/MPH/Internship/CPMC/Data/LD_reference/EUR",
              clump_kb = 1000, clump_r2 = .001, clump_p = 1, pop = "EUR")
    

  exposures_metabolite <- rbind(exposures_metabolite, metabolites_phenotypes)
    
}

exposures_metabolite <- exposures_metabolite %>% rename (SNP = rsid, id.exposure = id)  
  
#check that 'phenotypes' is the same as the last entry in metabolites_unique
metabolites_unique[121]
metabolites_phenotypes$phenotype


saveRDS(exposures_metabolite, file = "C:/Users/me/Desktop/MPH/Internship/CPMC/exposures_metabolites.rds")
```

#### f. Methylation Level QTLs
by cpg site and age



```{r}

#import Methylation Level QTLs into R
data(aries_mqtl)
aries_mqtl

#create a list of unique Methylation  cpg & make a list

methylation_unique <- aries_mqtl[!duplicated(aries_mqtl$cpg),]%>% pull(cpg)
age <- c("Birth", "Adolescence", "Childhood", "Middle age", "Pregnancy")
#  33256 unique cpg sites in catalog
# 5 'ages'

#make a for loop to create a database of exposure SNPs formatted for exposure data and clumped


exposures_methylation <- data.frame()
for (j in 1:5){
  for(i in 1 : 33256) {
  
    methylation_phenotypes<- subset(aries_mqtl, cpg == methylation_unique[i] & age == age[j])%>% 
      format_aries_mqtl() %>% 
      rename(rsid = SNP,
         pval = pval.exposure,
         id = id.exposure) %>%
    ld_clump( plink_bin = genetics.binaRies::get_plink_binary(), 
              bfile = "C:/Users/me/Desktop/MPH/Internship/CPMC/Data/LD_reference/EUR",
              clump_kb = 1000, clump_r2 = .001, clump_p = 1, pop = "EUR")
    
    
  exposures_methylation <- rbind(exposures_methylation, methylation_phenotypes)
     

    
    
  }


}

exposures_methylation <- exposures_methylation %>% rename (SNP = rsid, id.exposure = id)   
#check that 'phenotypes' is the same as the last entry in metabolites_unique
methylation_unique[33256]
methylation_phenotypes$cpg


saveRDS(exposures_methylation, file = "C:/Users/me/Desktop/MPH/Internship/CPMC/exposures_methylation.rds")
```


